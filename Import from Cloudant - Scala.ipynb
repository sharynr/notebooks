{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Scala example using Spark SQL over Cloudant as a source\n\nThis sample notebook is written in Scala and expects the Scala 2.11\nruntime. Make sure the kernel is started and connected when executing this notebook.\n\nThe data source for this example can be found at: http://examples.cloudant.com/crimes/. Replicate the database into your own Cloudant account before you execute this script.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## 1. Work with the Spark Context\n\nA Spark Context handle sc is available with every notebook create in the Spark Service. Use it to understand the Spark version used, the environment settings, \nand create a Spark SQL Context object off of it.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import org.apache.spark.sql.SparkSession", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "val spark = SparkSession.builder().getOrCreate()", 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## 2. Work with a Cloudant database\n\nA Dataframe object can be created directly from a Cloudant database. To configure the database as source, pass these options:\n\n1 - package name that provides the classes (like CloudantDataSource) implemented in the connector to extend BaseRelation. For the Cloudant Spark connector this will be org.apache.bahir.cloudant\n\n2 - cloudant.host parameter to pass the Cloudant account name\n\n3 - cloudant.user parameter to pass the Cloudant user name\n\n4 - cloudant.password parameter to pass the Cloudant account password\n\n5 - the database to load", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "val cloudantdata = sqlContext.read.format(\"org.apache.bahir.cloudant\").\noption(\"cloudant.host\",\"xxxxxx.cloudant.com\").\noption(\"cloudant.username\",\"xxxxxx\").\noption(\"cloudant.password\",\"xxxxxx\").\nload(\"crimes\")", 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## 3. Work with a Dataframe\n\nAt this point all transformations and functions should behave as specified with Spark SQL. (http://spark.apache.org/sql/)\n\nThis code prints the schema and a record count.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "cloudantdata.printSchema", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "This code displays the values of the naturecode field.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "val resultsDF = cloudantdata.select(\"properties.naturecode\")\nresultsDF.show()", 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "This code filters the data to just those records with a naturecode of \"DISTRB\", and then displays that data.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "val disturbDF = cloudantdata.filter(cloudantdata.col(\"properties.naturecode\").startsWith(\"DISTRB\"))\ndisturbDF.show()", 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "This code writes the filtered data to a Cloudant database called crimes_filtered. If the Cloudant database exists, the documents will be added to the database. If the database does not exist, set the createDBOnSave option to \"true\".", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "disturbDF.select(\"properties\").write.format(\"org.apache.bahir.cloudant\").\noption(\"cloudant.host\",\"xxxxxxx.cloudant.com\").\noption(\"cloudant.username\",\"xxxxxxxx\").\noption(\"cloudant.password\",\"xxxxxxxx\").\noption(\"createDBOnSave\", \"false\").\nsave(\"crimes_filtered\")", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Scala 2.11 with Spark", 
            "name": "scala", 
            "language": "scala"
        }, 
        "language_info": {
            "mimetype": "text/x-scala", 
            "version": "2.11.12", 
            "name": "scala", 
            "pygments_lexer": "scala", 
            "file_extension": ".scala", 
            "codemirror_mode": "text/x-scala"
        }
    }, 
    "nbformat": 4
}